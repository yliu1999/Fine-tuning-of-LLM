import gradio as gr
import requests
import time

# APIé…ç½®
API_URL = "http://localhost:8000/ask"


def mock_response(message):
    """æ¨¡æ‹Ÿåç«¯å“åº”ï¼Œç”¨äºæµ‹è¯•"""
    mock_responses = {
        "ç³–å°¿ç—…çš„å…¸å‹ç—‡çŠ¶æœ‰å“ªäº›ï¼Ÿ": "ç³–å°¿ç—…çš„å…¸å‹ç—‡çŠ¶åŒ…æ‹¬å¤šé¥®ã€å¤šé£Ÿã€å¤šå°¿å’Œä½“é‡å‡è½»ï¼Œå³'ä¸‰å¤šä¸€å°‘'ç—‡çŠ¶ã€‚æ­¤å¤–è¿˜å¯èƒ½å‡ºç°ç–²åŠ³ã€è§†åŠ›æ¨¡ç³Šç­‰ç—‡çŠ¶ã€‚",
        "å¦‚ä½•æœ‰æ•ˆé¢„é˜²é«˜è¡€å‹ï¼Ÿ": "é¢„é˜²é«˜è¡€å‹åº”ä¿æŒå¥åº·é¥®é£Ÿï¼Œå‡å°‘ç›çš„æ‘„å…¥ï¼ŒåšæŒé€‚é‡è¿åŠ¨ï¼Œä¿æŒå¥åº·ä½“é‡ï¼Œæˆ’çƒŸé™é…’ï¼Œä¿æŒè‰¯å¥½çš„å¿ƒæ€å’Œå……è¶³çš„ç¡çœ ã€‚",
        "æ™®é€šæ„Ÿå†’å’Œæµæ„Ÿçš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ": "æ™®é€šæ„Ÿå†’ç—‡çŠ¶è¾ƒè½»ï¼Œä¸»è¦è¡¨ç°ä¸ºé¼»å¡ã€æµæ¶•ã€å’½ç—›ç­‰ä¸Šå‘¼å¸é“ç—‡çŠ¶ï¼›æµæ„Ÿç—‡çŠ¶è¾ƒé‡ï¼Œå¸¸ä¼´æœ‰é«˜çƒ­ã€å…¨èº«é…¸ç—›ã€ä¹åŠ›ç­‰å…¨èº«ç—‡çŠ¶ï¼Œä¼ æŸ“æ€§ä¹Ÿæ›´å¼ºã€‚"
    }
    # å¦‚æœæ²¡æœ‰åŒ¹é…çš„é¢„è®¾é—®é¢˜ï¼Œè¿”å›é€šç”¨å›ç­”
    return mock_responses.get(message,
                              f"è¿™æ˜¯æ¨¡æ‹Ÿçš„å›ç­”ã€‚ä½ é—®çš„æ˜¯ï¼š{message}\n\næ³¨æ„ï¼šå½“å‰å¤„äºç¦»çº¿æ¨¡å¼ï¼Œå®é™…ä½¿ç”¨æ—¶è¯·å¯åŠ¨åç«¯æœåŠ¡ã€‚")


# def chat_with_model(message, history):
#     """ä¸åŒ»ç–—æ¨¡å‹å¯¹è¯ï¼šè¿”å›ç¬¦åˆGradio Chatbotè¦æ±‚çš„æ ¼å¼"""
#     # åˆå§‹åŒ–å†å²å¯¹è¯ï¼ˆè‹¥ä¸ºç©ºåˆ™åˆ›å»ºç©ºåˆ—è¡¨ï¼‰
#     history = history or []
#     try:
#         # 1. è°ƒç”¨åç«¯API
#         response = requests.post(API_URL, json={
#             "question": message,  # å·²ä¿®æ­£ä¸ºæ­£ç¡®çš„å‚æ•°å
#             "max_tokens": 300,
#             "temperature": 0.7
#         })
#
#         # 2. å¤„ç†APIå“åº”
#         if response.status_code == 200:
#             result = response.json()
#             model_answer = result["answer"]  # è·å–æ¨¡å‹å›ç­”
#             # 3. æ›´æ–°å¯¹è¯å†å²ï¼šåœ¨åŸæœ‰å†å²ä¸­æ·»åŠ â€œ(ç”¨æˆ·é—®é¢˜, æ¨¡å‹å›ç­”)â€
#             history.append((message, model_answer))
#             # 4. è¿”å›æ›´æ–°åçš„å†å²ï¼ˆç¬¦åˆChatbotæ ¼å¼è¦æ±‚ï¼‰
#             return history
#         else:
#             # è‹¥APIè¯·æ±‚å¤±è´¥ï¼Œä¹Ÿæ·»åŠ é”™è¯¯ä¿¡æ¯åˆ°å†å²
#             error_msg = f"APIè¯·æ±‚å¤±è´¥: {response.status_code}"
#             history.append((message, error_msg))
#             return history
#
#     except Exception as e:
#         # è‹¥å‘ç”Ÿå¼‚å¸¸ï¼Œæ·»åŠ å¼‚å¸¸ä¿¡æ¯åˆ°å†å²
#         error_msg = f"å‘ç”Ÿé”™è¯¯: {str(e)}"
#         history.append((message, error_msg))
#         return history


def chat_with_model(message, history, temperature, max_tokens, offline_mode):
    """ä¸åŒ»ç–—æ¨¡å‹å¯¹è¯ï¼Œæ”¯æŒç¦»çº¿æ¨¡å¼"""
    if not message.strip():
        return history, "âŒ é—®é¢˜ä¸èƒ½ä¸ºç©º", ""

    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
    history.append([message, ""])

    try:
        if offline_mode:
            # ä½¿ç”¨æ¨¡æ‹Ÿå“åº”
            answer = mock_response(message)
            # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
            time.sleep(1)
            history[-1][1] = answer
            return history, "âœ… ç¦»çº¿æ¨¡å¼ - å›ç­”å®Œæˆ", ""
        else:
            # è°ƒç”¨API
            response = requests.post(API_URL, json={
                "question": message,
                "max_tokens": max_tokens,
                "temperature": temperature
            }, timeout=60)

            if response.status_code == 200:
                result = response.json()
                answer = result["answer"]
                history[-1][1] = answer
                return history, "âœ… å›ç­”å®Œæˆ", ""
            else:
                history[-1][1] = f"âŒ APIè¯·æ±‚å¤±è´¥: {response.status_code}"
                return history, "âŒ è¯·æ±‚å¤±è´¥", ""

    except Exception as e:
        error_msg = f"âŒ å‘ç”Ÿé”™è¯¯: {str(e)}"
        history[-1][1] = error_msg
        # ç‰¹åˆ«æç¤ºåç«¯æœªå¯åŠ¨çš„æƒ…å†µ
        if "Connection refused" in str(e) or "Failed to connect" in str(e):
            return history, "âŒ åç«¯æœåŠ¡æœªå¯åŠ¨ï¼Œè¯·ç¡®ä¿åç«¯æœåŠ¡è¿è¡Œåœ¨8000ç«¯å£", ""
        return history, "âŒ é”™è¯¯", ""


def clear_chat():
    """æ¸…ç©ºèŠå¤©è®°å½•"""
    return [], "èŠå¤©è®°å½•å·²æ¸…ç©º", ""


def create_fixed_interface():
    """åˆ›å»ºä¿®å¤åçš„ç•Œé¢"""
    with gr.Blocks(title="æ™ºèƒ½åŒ»ç–—åŠ©æ‰‹", theme=gr.themes.Soft()) as demo:

        # å¤´éƒ¨åŒºåŸŸ
        gr.Markdown("""
        # ğŸ¥ æ™ºèƒ½åŒ»ç–—é—®ç­”åŠ©æ‰‹
        **åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ä¸“ä¸šåŒ»ç–—å’¨è¯¢å¹³å°**
        """)

        with gr.Row():
            # å·¦ä¾§èŠå¤©åŒºåŸŸ
            with gr.Column(scale=3):
                chatbot = gr.Chatbot(
                    label="ğŸ’¬ åŒ»ç–—å¯¹è¯",
                    height=400,
                    show_copy_button=True
                )

                with gr.Row():
                    msg = gr.Textbox(
                        label="ğŸ“ è¾“å…¥æ‚¨çš„é—®é¢˜",
                        placeholder="è¯·è¾“å…¥åŒ»ç–—ç›¸å…³é—®é¢˜... æŒ‰Ctrl+Enterå‘é€ï¼Œæˆ–ç‚¹å‡»å‘é€æŒ‰é’®",
                        lines=2,
                        max_lines=4,
                        scale=4
                    )
                    submit_btn = gr.Button("ğŸš€ å‘é€", size="lg", scale=1)

                with gr.Row():
                    clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯")

            # å³ä¾§æ§åˆ¶é¢æ¿
            with gr.Column(scale=1):
                gr.Markdown("### âš™ï¸ å‚æ•°è®¾ç½®")

                # æ·»åŠ ç¦»çº¿æ¨¡å¼å¼€å…³
                offline_mode = gr.Checkbox(label="ç¦»çº¿æ¨¡å¼", value=False,
                                           info="å¯ç”¨åä¸è¿æ¥åç«¯ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")

                temperature = gr.Slider(0.1, 1.0, value=0.7, label="åˆ›é€ æ€§")
                max_tokens = gr.Slider(50, 500, value=300, step=50, label="å›ç­”é•¿åº¦")

                gr.Markdown("### ğŸ’¡ ç¤ºä¾‹é—®é¢˜")
                example_questions = [
                    "ç³–å°¿ç—…çš„å…¸å‹ç—‡çŠ¶æœ‰å“ªäº›ï¼Ÿ",
                    "å¦‚ä½•æœ‰æ•ˆé¢„é˜²é«˜è¡€å‹ï¼Ÿ",
                    "æ™®é€šæ„Ÿå†’å’Œæµæ„Ÿçš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ"
                ]

                for question in example_questions:
                    btn = gr.Button(question, size="sm")
                    btn.click(lambda q=question: q, outputs=[msg])

                status = gr.Textbox(label="çŠ¶æ€", value="ğŸŸ¢ ç³»ç»Ÿå°±ç»ª", interactive=False)

        # æ­£ç¡®çš„äº¤äº’é€»è¾‘
        def submit_message(message, history, temp, tokens, offline):
            if not message.strip():
                return history, "âŒ é—®é¢˜ä¸èƒ½ä¸ºç©º", ""
            return chat_with_model(message, history, temp, tokens, offline)

        # æŒ‰é’®ç‚¹å‡»äº‹ä»¶
        submit_btn.click(
            fn=submit_message,
            inputs=[msg, chatbot, temperature, max_tokens, offline_mode],
            outputs=[chatbot, status, msg]
        )

        # æ–‡æœ¬æ¡†æäº¤äº‹ä»¶ï¼ˆä½¿ç”¨Ctrl+Enterï¼‰
        msg.submit(
            fn=submit_message,
            inputs=[msg, chatbot, temperature, max_tokens, offline_mode],
            outputs=[chatbot, status, msg]
        )

        # æ¸…ç©ºæŒ‰é’®
        clear_btn.click(
            fn=clear_chat,
            outputs=[chatbot, status, msg]
        )

        # ç¦»çº¿æ¨¡å¼åˆ‡æ¢æç¤º
        def update_status(offline):
            if offline:
                return "ğŸŸ¡ ç¦»çº¿æ¨¡å¼ - ä¸è¿æ¥åç«¯æœåŠ¡"
            else:
                return "ğŸŸ¢ åœ¨çº¿æ¨¡å¼ - å‡†å¤‡è¿æ¥åç«¯æœåŠ¡"

        offline_mode.change(
            fn=update_status,
            inputs=[offline_mode],
            outputs=[status]
        )

    return demo


if __name__ == "__main__":
    demo = create_fixed_interface()
    demo.launch(server_name="0.0.0.0", server_port=7860)
